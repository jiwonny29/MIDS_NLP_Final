{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import plotly.express as px\n",
    "import matplotlib as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize  # Import word_tokenize function\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\ayush\\\\OneDrive\\\\Desktop\\\\NLP\\\\Final Project\\\\Train_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76637</th>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>After seeing the Altoids advertisement in Amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64372</th>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>I am so disappointed with these almonds.  They...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252387</th>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Great product. Great packaging.&lt;br /&gt;&lt;br /&gt;I o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251573</th>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Purchased original can at Walmart. Of course, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318742</th>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I was very happy with this product.  You could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188636</th>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Everything was good about this jerky except th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117743</th>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>I bought this product along with Dr. McDougall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166855</th>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Nothing wrong with the product - I buy it in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138409</th>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a great product-my dog loves these. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36407</th>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>I did NOT like this lemon lime flavor.  It mad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  rating  sentiment  \\\n",
       "76637   negative       1         -1   \n",
       "64372   negative       1         -1   \n",
       "252387  positive       5          1   \n",
       "251573  positive       5          1   \n",
       "318742  positive       5          1   \n",
       "...          ...     ...        ...   \n",
       "188636   neutral       3          0   \n",
       "117743  negative       1         -1   \n",
       "166855   neutral       3          0   \n",
       "138409   neutral       3          0   \n",
       "36407   negative       1         -1   \n",
       "\n",
       "                                                   review  \n",
       "76637   After seeing the Altoids advertisement in Amaz...  \n",
       "64372   I am so disappointed with these almonds.  They...  \n",
       "252387  Great product. Great packaging.<br /><br />I o...  \n",
       "251573  Purchased original can at Walmart. Of course, ...  \n",
       "318742  I was very happy with this product.  You could...  \n",
       "...                                                   ...  \n",
       "188636  Everything was good about this jerky except th...  \n",
       "117743  I bought this product along with Dr. McDougall...  \n",
       "166855  Nothing wrong with the product - I buy it in t...  \n",
       "138409  This is a great product-my dog loves these. I ...  \n",
       "36407   I did NOT like this lemon lime flavor.  It mad...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data.sample(n=100000, random_state=42)\n",
    "\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.sentiment.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(text):\n",
    "    text = text.lower()  # Making everthing in lower case\n",
    "    text = re.sub(\"<br />\", \"\", text)  # removing breaks\n",
    "    text = re.sub(\n",
    "        r\"https\\S+|www\\S+|http\\S+\", \"\", text, flags=re.MULTILINE\n",
    "    )  # removing links\n",
    "    text = re.sub(r\"\\@w+|\\#\", \"\", text)  # removing @ and #\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # removing punctuations\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_text = [\n",
    "        w for w in text_tokens if not w in stop_words\n",
    "    ]  # removing stop words\n",
    "    return \" \".join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.review = data1[\"review\"].apply(data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries:  26906\n"
     ]
    }
   ],
   "source": [
    "duplicated_count = data1.duplicated().sum()\n",
    "print(\"Number of duplicate entries: \", duplicated_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop_duplicates(\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()  # Stemming for text normalization\n",
    "\n",
    "\n",
    "def stemming(data):\n",
    "    text = [stemmer.stem(word) for word in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_42660\\3135491822.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1.review = data1['review'].apply(lambda x: stemming(x))\n"
     ]
    }
   ],
   "source": [
    "data1.review = data1[\"review\"].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 531325),\n",
       " ('I', 446809),\n",
       " ('and', 367314),\n",
       " ('a', 355873),\n",
       " ('to', 312102),\n",
       " ('of', 250670),\n",
       " ('is', 218635),\n",
       " ('it', 206933),\n",
       " ('in', 158855),\n",
       " ('this', 157945),\n",
       " ('for', 155384),\n",
       " ('that', 129385),\n",
       " ('was', 111046),\n",
       " ('but', 109453),\n",
       " ('my', 107818)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter  # counting the most common words\n",
    "\n",
    "count = Counter()\n",
    "for text in data1[\"review\"].values:\n",
    "    for word in text.split():\n",
    "        count[word] += 1\n",
    "count.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1.review\n",
    "y = data1.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, max_features=7000)\n",
    "\n",
    "\n",
    "tfidf_data = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tfidf_data.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>0g</th>\n",
       "      <th>0mg</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>ziplock</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuke</th>\n",
       "      <th>zukes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   03   05   06   07   08   09   0g  0mg  ...  zip  ziploc  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0     0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0     0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0     0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0     0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0     0.0   \n",
       "\n",
       "   ziplock  zipper  zoe  zone  zoom  zucchini  zuke  zukes  \n",
       "0      0.0     0.0  0.0   0.0   0.0       0.0   0.0    0.0  \n",
       "1      0.0     0.0  0.0   0.0   0.0       0.0   0.0    0.0  \n",
       "2      0.0     0.0  0.0   0.0   0.0       0.0   0.0    0.0  \n",
       "3      0.0     0.0  0.0   0.0   0.0       0.0   0.0    0.0  \n",
       "4      0.0     0.0  0.0   0.0   0.0       0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 7000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    tfidf_data, y, test_size=0.3, random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(\n",
    "    xtrain, ytrain\n",
    ")  # using multinomial Naive bayes to train and test\n",
    "\n",
    "predicted = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7075567087013755\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\", metrics.accuracy_score(ytest, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5922506057195185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    ")  # using Gaussian Naive bayes to train and test\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    tfidf_data.toarray(), y, test_size=0.3, random_state=2\n",
    ")\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the Gaussian Naive Bayes classifier\n",
    "gnb.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict on test set\n",
    "predicted = gnb.predict(xtest)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(ytest, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1      2\n",
      "0  8599  4508   2249\n",
      "1  2564  4273   2362\n",
      "2  3592  6098  18172\n"
     ]
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(ytest, predicted)\n",
    "\n",
    "# Convert confusion matrix array to a DataFrame\n",
    "confusion_df = pd.DataFrame(conf_mat)\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I had a good today\"\n",
    "random_sentence_tfidf = vectorizer.transform([sentence])\n",
    "\n",
    "predicted_class = clf.predict(random_sentence_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 75.70%\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(xtrain, ytrain)\n",
    "logreg_pred = logreg.predict(xtest)\n",
    "logreg_acc = accuracy_score(logreg_pred, ytest)\n",
    "print(\"Test accuracy: {:.2f}%\".format(logreg_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
